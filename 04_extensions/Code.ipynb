{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains experiments for:\n",
    "\n",
    "* Loss functions\n",
    "* Learning rate decay\n",
    "* Optimizers\n",
    "* Weight initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `lincoln` imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lincoln import activations\n",
    "from lincoln import layers\n",
    "from lincoln import losses\n",
    "from lincoln import optimizers\n",
    "from lincoln import network\n",
    "from lincoln import train\n",
    "from lincoln.utils import mnist\n",
    "\n",
    "RANDOM_SEED = 190119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = mnist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(y_train)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "num_labels = len(y_train)\n",
    "train_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    train_labels[i][y_train[i]] = 1\n",
    "\n",
    "num_labels = len(y_test)\n",
    "test_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    test_labels[i][y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data to mean 0, variance 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train - np.mean(X_train), X_test - np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-33.318421449829934,\n",
       " 221.68157855017006,\n",
       " -33.318421449829934,\n",
       " 221.68157855017006)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / np.std(X_train), X_test / np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.424073894391566, 2.821543345689335, -0.424073894391566, 2.821543345689335)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_model(model, test_set):\n",
    "    return print(\n",
    "        '''The model validation accuracy is: {0:.2f}%'''.format(\n",
    "            np.equal(np.argmax(model.forward(test_set), axis=1), y_test).sum()\n",
    "            * 100.0\n",
    "            / test_set.shape[0]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 5 epochs is 0.836\n",
      "Validation loss after 10 epochs is 0.718\n",
      "Validation loss after 15 epochs is 0.659\n",
      "Validation loss after 20 epochs is 0.638\n",
      "Validation loss after 25 epochs is 0.627\n",
      "Validation loss after 30 epochs is 0.619\n",
      "Validation loss after 35 epochs is 0.558\n",
      "Validation loss after 40 epochs is 0.506\n",
      "Validation loss after 45 epochs is 0.499\n",
      "Validation loss after 50 epochs is 0.495\n",
      "The model validation accuracy is: 57.16%\n"
     ]
    }
   ],
   "source": [
    "model = network.NeuralNetwork(\n",
    "    layers=[\n",
    "        layers.Dense(neurons=89, activation=activations.Sigmoid()),\n",
    "        layers.Dense(neurons=10, activation=activations.Sigmoid()),\n",
    "    ],\n",
    "    loss=losses.MeanSquaredError(normalize=False),\n",
    "    seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "trainer = train.Trainer(model, optimizers.SGD(0.1))\n",
    "trainer.fit(\n",
    "    X_train,\n",
    "    train_labels,\n",
    "    X_test,\n",
    "    test_labels,\n",
    "    epochs=50,\n",
    "    eval_every=5,\n",
    "    seed=RANDOM_SEED,\n",
    "    batch_size=60,\n",
    ")\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: even if we normalize the outputs of a classification model with mean squared error loss, it still doesn't help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 5 epochs is 0.573\n",
      "\n",
      "Loss increased after epoch 10, final loss was 0.573, \n",
      "using the model from epoch 5\n",
      "The model validation accuracy is: 62.54%\n"
     ]
    }
   ],
   "source": [
    "model = network.NeuralNetwork(\n",
    "    layers=[\n",
    "        layers.Dense(neurons=89, activation=activations.Sigmoid()),\n",
    "        layers.Dense(neurons=10, activation=activations.Sigmoid()),\n",
    "    ],\n",
    "    loss=losses.MeanSquaredError(normalize=True),\n",
    "    seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "trainer = train.Trainer(model, optimizers.SGD(0.1))\n",
    "trainer.fit(\n",
    "    X_train,\n",
    "    train_labels,\n",
    "    X_test,\n",
    "    test_labels,\n",
    "    epochs=50,\n",
    "    eval_every=5,\n",
    "    seed=RANDOM_SEED,\n",
    "    batch_size=60,\n",
    ")\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is that we should be using softmax cross entropy loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 5 epochs is 0.719\n",
      "Validation loss after 10 epochs is 0.611\n",
      "Validation loss after 15 epochs is 0.559\n",
      "Validation loss after 20 epochs is 0.530\n",
      "Validation loss after 25 epochs is 0.505\n",
      "Validation loss after 30 epochs is 0.488\n",
      "Validation loss after 35 epochs is 0.475\n",
      "Validation loss after 40 epochs is 0.467\n",
      "Validation loss after 45 epochs is 0.459\n",
      "Validation loss after 50 epochs is 0.453\n",
      "\n",
      "The model validation accuracy is: 92.61%\n"
     ]
    }
   ],
   "source": [
    "model = network.NeuralNetwork(\n",
    "    layers=[\n",
    "        layers.Dense(neurons=89, activation=activations.Sigmoid()),\n",
    "        layers.Dense(neurons=10, activation=activations.Linear()),\n",
    "    ],\n",
    "    loss=losses.SoftmaxCrossEntropy(),\n",
    "    seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "trainer = train.Trainer(model, optimizers.SGD(0.1))\n",
    "trainer.fit(\n",
    "    X_train,\n",
    "    train_labels,\n",
    "    X_test,\n",
    "    test_labels,\n",
    "    epochs=50,\n",
    "    eval_every=5,\n",
    "    seed=RANDOM_SEED,\n",
    "    batch_size=60,\n",
    ")\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 5 epochs is 0.413\n",
      "Validation loss after 10 epochs is 0.361\n",
      "\n",
      "Loss increased after epoch 15, final loss was 0.361, \n",
      "using the model from epoch 10\n",
      "The model validation accuracy is: 94.10%\n"
     ]
    }
   ],
   "source": [
    "model = network.NeuralNetwork(\n",
    "    layers=[\n",
    "        layers.Dense(neurons=89, activation=activations.Sigmoid()),\n",
    "        layers.Dense(neurons=10, activation=activations.Linear()),\n",
    "    ],\n",
    "    loss=losses.SoftmaxCrossEntropy(),\n",
    "    seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "optim = optimizers.SGDMomentum(0.1, momentum=0.9)\n",
    "\n",
    "trainer = train.Trainer(model, optim)\n",
    "trainer.fit(\n",
    "    X_train,\n",
    "    train_labels,\n",
    "    X_test,\n",
    "    test_labels,\n",
    "    epochs=50,\n",
    "    eval_every=5,\n",
    "    seed=RANDOM_SEED,\n",
    "    batch_size=60,\n",
    ")\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 5 epochs is 0.376\n",
      "Validation loss after 10 epochs is 0.328\n",
      "\n",
      "Loss increased after epoch 15, final loss was 0.328, \n",
      "using the model from epoch 10\n",
      "The model validation accuracy is: 94.76%\n"
     ]
    }
   ],
   "source": [
    "model = network.NeuralNetwork(\n",
    "    layers=[\n",
    "        layers.Dense(neurons=89, activation=activations.Sigmoid()),\n",
    "        layers.Dense(neurons=10, activation=activations.Linear()),\n",
    "    ],\n",
    "    loss=losses.SoftmaxCrossEntropy(),\n",
    "    seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "optimizer = optimizers.SGDMomentum(0.15, momentum=0.9, final_lr=0.05, decay_type='linear')\n",
    "\n",
    "trainer = train.Trainer(model, optimizer)\n",
    "trainer.fit(\n",
    "    X_train,\n",
    "    train_labels,\n",
    "    X_test,\n",
    "    test_labels,\n",
    "    epochs=25,\n",
    "    eval_every=5,\n",
    "    seed=RANDOM_SEED,\n",
    "    batch_size=60,\n",
    ")\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 5 epochs is 0.387\n",
      "Validation loss after 10 epochs is 0.336\n",
      "\n",
      "Loss increased after epoch 15, final loss was 0.336, \n",
      "using the model from epoch 10\n",
      "The model validation accuracy is: 94.81%\n"
     ]
    }
   ],
   "source": [
    "model = network.NeuralNetwork(\n",
    "    layers=[\n",
    "        layers.Dense(neurons=89, activation=activations.Sigmoid()),\n",
    "        layers.Dense(neurons=10, activation=activations.Linear()),\n",
    "    ],\n",
    "    loss=losses.SoftmaxCrossEntropy(),\n",
    "    seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "optimizer = optimizers.SGDMomentum(0.2, momentum=0.9, final_lr=0.05, decay_type='exponential')\n",
    "\n",
    "trainer = train.Trainer(model, optimizer)\n",
    "trainer.fit(\n",
    "    X_train,\n",
    "    train_labels,\n",
    "    X_test,\n",
    "    test_labels,\n",
    "    epochs=25,\n",
    "    eval_every=5,\n",
    "    seed=RANDOM_SEED,\n",
    "    batch_size=60,\n",
    ")\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing weight init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 5 epochs is 0.169\n",
      "Validation loss after 10 epochs is 0.160\n",
      "\n",
      "Loss increased after epoch 15, final loss was 0.160, \n",
      "using the model from epoch 10\n",
      "The model validation accuracy is: 97.46%\n"
     ]
    }
   ],
   "source": [
    "model = network.NeuralNetwork(\n",
    "    layers=[\n",
    "        layers.Dense(neurons=89, activation=activations.Sigmoid(), weight_init=\"glorot\"),\n",
    "        layers.Dense(neurons=10, activation=activations.Linear(), weight_init=\"glorot\"),\n",
    "    ],\n",
    "    loss=losses.SoftmaxCrossEntropy(),\n",
    "    seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "optimizer = optimizers.SGDMomentum(0.2, momentum=0.9, final_lr=0.05, decay_type='exponential')\n",
    "\n",
    "trainer = train.Trainer(model, optimizer)\n",
    "trainer.fit(\n",
    "    X_train,\n",
    "    train_labels,\n",
    "    X_test,\n",
    "    test_labels,\n",
    "    epochs=25,\n",
    "    eval_every=5,\n",
    "    seed=RANDOM_SEED,\n",
    "    batch_size=60,\n",
    ")\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
